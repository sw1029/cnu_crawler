# src/cnu_crawler/spiders/colleges.py
import asyncio
import re
from typing import List, Dict, Optional
from urllib.parse import urljoin

from loguru import logger
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
# BeautifulSoupì„ ì‚¬ìš©í•˜ê¸° ìœ„í•œ import (ì„ íƒì , Seleniumë§Œìœ¼ë¡œë„ ê°€ëŠ¥í•˜ë‚˜ ë³µì¡í•œ HTML íŒŒì‹±ì— ìœ ë¦¬)
# from bs4 import BeautifulSoup

from cnu_crawler.core.browser import get_driver
from cnu_crawler.core.fetcher import fetch_text  # ì •ì  í˜ì´ì§€ HTML ê°€ì ¸ì˜¤ê¸°ìš©
from cnu_crawler.core.parser import html_select  # BeautifulSoup ê¸°ë°˜ íŒŒì„œ í—¬í¼
from cnu_crawler.storage import College, get_session
from cnu_crawler.utils import clean_text
from cnu_crawler.config import ROOT_URL  #


# --- Helper Functions ---
def _generate_college_code(name: str, prefix: str = "coll") -> str:
    """ëŒ€í•™ ì´ë¦„ê³¼ ì ‘ë‘ì‚¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê³ ìœ  ì½”ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    cleaned_name = re.sub(r'\s+', '', name.lower())  # ê³µë°± ì œê±°, ì†Œë¬¸ìí™”
    # í•œê¸€ ë“± ë¹„-ì•ŒíŒŒë²³ ë¬¸ì ì²˜ë¦¬ (ê°„ë‹¨íˆ ì œê±° ë˜ëŠ” ì˜ë¬¸ ìŒì°¨ ë³€í™˜ ê³ ë ¤)
    # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ë¹„-ì•ŒíŒŒë²³ë¬¸ì ì œê±° í›„ ì•ë¶€ë¶„ ì‚¬ìš©
    alnum_name = re.sub(r'[^a-z0-9]', '', cleaned_name)
    return f"{prefix}_{alnum_name[:20]}_{hash(name)[:6]}"  # ì´ë¦„ í•´ì‹œ ì¼ë¶€ ì¶”ê°€í•˜ì—¬ ê³ ìœ ì„± ì¦ëŒ€


def _save_colleges_to_db(colleges_data: List[Dict], log_prefix: str):
    """ìˆ˜ì§‘ëœ College ì •ë³´ë¥¼ DBì— ì €ì¥í•˜ê±°ë‚˜ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
    if not colleges_data:
        logger.info(f"[{log_prefix}] DBì— ì €ì¥í•  College ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    with get_session() as sess:
        added_count = 0
        updated_count = 0
        for c_data in colleges_data:
            # codeëŠ” ë°˜ë“œì‹œ ê³ ìœ í•´ì•¼ í•¨
            existing_college = sess.query(College).filter_by(code=c_data["code"]).one_or_none()
            if existing_college:
                changed = False
                if existing_college.name != c_data["name"]:
                    existing_college.name = c_data["name"]
                    changed = True
                if existing_college.url != c_data["url"]:
                    existing_college.url = c_data["url"]
                    changed = True
                if existing_college.college_type != c_data.get("college_type", existing_college.college_type):
                    existing_college.college_type = c_data.get("college_type", existing_college.college_type)
                    changed = True

                if changed:
                    updated_count += 1
                    logger.trace(f"[{log_prefix}] ê¸°ì¡´ College ì—…ë°ì´íŠ¸: code='{c_data['code']}', name='{c_data['name']}'")
            else:
                new_college = College(**c_data)
                sess.add(new_college)
                added_count += 1
                logger.trace(f"[{log_prefix}] ìƒˆ College ì¶”ê°€: code='{c_data['code']}', name='{c_data['name']}'")

        if added_count > 0 or updated_count > 0:
            try:
                sess.commit()
                logger.success(f"[{log_prefix}] College ì •ë³´ DB ì—…ë°ì´íŠ¸: {added_count}ê°œ ì¶”ê°€, {updated_count}ê°œ ìˆ˜ì •.")
            except Exception as e_db:
                logger.opt(exception=True).error(f"[{log_prefix}] College ì •ë³´ DB ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e_db}")
                sess.rollback()
        else:
            logger.info(f"[{log_prefix}] DBì— ë³€ê²½ëœ College ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")


# --- Main Discover Functions ---

async def discover_plus_normal_colleges(root_url: str = ROOT_URL) -> List[Dict]:
    """
    ROOT_URL (plus.cnu.ac.kr)ì—ì„œ ì¼ë°˜ ë‹¨ê³¼ëŒ€í•™ ëª©ë¡ì„ íŒŒì‹±í•©ë‹ˆë‹¤.
    XPath: /html/body/div[3]/div/div[3] (ì»¨í…Œì´ë„ˆ)
           .//ul//li/a (ê°œë³„ ëŒ€í•™ ë§í¬)
    """
    logger.info(f"ğŸ” ì¼ë°˜ ë‹¨ê³¼ëŒ€í•™ ëª©ë¡ íƒìƒ‰ ì‹œì‘ (ì¶œì²˜: {root_url})")
    colleges_data: List[Dict] = []
    # ì œê³µëœ XPath
    COLLEGES_CONTAINER_XPATH = "/html/body/div[3]/div/div[3]"
    INDIVIDUAL_COLLEGE_LINK_XPATH = ".//ul//li/a"

    try:
        with get_driver() as driver:  # Selenium ì‚¬ìš©
            driver.get(root_url)
            WebDriverWait(driver, 15).until(
                EC.presence_of_element_located((By.XPATH, COLLEGES_CONTAINER_XPATH))
            )
            container_element = driver.find_element(By.XPATH, COLLEGES_CONTAINER_XPATH)
            college_link_elements = container_element.find_elements(By.XPATH, INDIVIDUAL_COLLEGE_LINK_XPATH)

            if not college_link_elements:
                logger.warning(
                    f"[{root_url}] ì»¨í…Œì´ë„ˆ('{COLLEGES_CONTAINER_XPATH}') ë‚´ì—ì„œ ëŒ€í•™ ë§í¬ ('{INDIVIDUAL_COLLEGE_LINK_XPATH}')ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                return []

            logger.info(f"[{root_url}] {len(college_link_elements)}ê°œì˜ ì¼ë°˜ ë‹¨ê³¼ëŒ€í•™ ë§í¬ í›„ë³´ ë°œê²¬.")
            for idx, link_element in enumerate(college_link_elements):
                college_name_raw = link_element.get_attribute("textContent")
                college_name = clean_text(college_name_raw if college_name_raw else "")
                college_url_raw = link_element.get_attribute("href")

                if not college_name or not college_url_raw:
                    logger.warning(f"ì¼ë°˜ ë‹¨ê³¼ëŒ€í•™ ë§í¬ì—ì„œ ì´ë¦„ ë˜ëŠ” URL ëˆ„ë½ (ì¸ë±ìŠ¤: {idx}). ê±´ë„ˆëœë‹ˆë‹¤.")
                    continue

                college_url = urljoin(root_url, college_url_raw)

                # ëŒ€í•™ ì½”ë“œ ìƒì„± (ëŒ€í•™ ì´ë¦„ ê¸°ë°˜, ì ‘ë‘ì‚¬ ì‚¬ìš©)
                college_code = _generate_college_code(college_name, prefix="plus_normal")

                colleges_data.append({
                    "code": college_code,
                    "name": college_name,
                    "url": college_url,
                    "college_type": "normal_college"  # ëª¨ë¸ì— ì •ì˜ëœ íƒ€ì… ì‚¬ìš©
                })

        _save_colleges_to_db(colleges_data, "Plus ì¼ë°˜ ë‹¨ê³¼ëŒ€í•™")
        return colleges_data
    except Exception as e:
        logger.opt(exception=True).error(f"Plus ì¼ë°˜ ë‹¨ê³¼ëŒ€í•™ ëª©ë¡ íƒìƒ‰ ì¤‘ ì˜ˆì™¸: {e}")
        return []


async def discover_grad_page_colleges_and_depts(grad_info_url: str = "https://grad.cnu.ac.kr/grad/grad/normal-grad.do"):
    """
    grad.cnu.ac.kr í˜ì´ì§€ì—ì„œ 'ëŒ€í•™ëª…'(h4)ì„ Collegeë¡œ, ê·¸ í•˜ìœ„ í•™ê³¼(ul/li/a)ë¥¼ Departmentë¡œ íŒŒì‹±í•©ë‹ˆë‹¤.
    ì´ í•¨ìˆ˜ëŠ” Collegeì™€ Department ì •ë³´ë¥¼ í•¨ê»˜ ì²˜ë¦¬í•˜ê±°ë‚˜, College ì •ë³´ë§Œ ë°˜í™˜í•˜ê³  Department íŒŒì‹±ì€
    departments.pyì—ì„œ í•˜ë„ë¡ ì—­í•  ë¶„ë‹´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” College ì •ë³´ë§Œ ìš°ì„  ìƒì„±í•©ë‹ˆë‹¤.
    Department ì •ë³´ëŠ” departments.pyì—ì„œ ì´ College ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ íŒŒì‹±í•˜ë„ë¡ í•©ë‹ˆë‹¤.
    """
    logger.info(f"ğŸ“ ì¼ë°˜ëŒ€í•™ì› í˜ì´ì§€({grad_info_url})ì—ì„œ 'ëŒ€í•™' ë‹¨ìœ„(ì†Œì†) íƒìƒ‰ ì‹œì‘...")
    colleges_data: List[Dict] = []

    try:
        html_content = await fetch_text(grad_info_url)  # ì •ì  HTML ê°€ì •

        # ì‚¬ìš©ì ì œê³µ XPath: /html/body/div[1]/div[3]/div[2]/div[3]/div/div/div[1]/h4 ëŒ€í•™ëª…
        # ì´ XPathëŠ” ì²« ë²ˆì§¸ 'ëŒ€í•™ëª…'ë§Œ ê°€ë¦¬í‚µë‹ˆë‹¤. ëª¨ë“  'ëŒ€í•™ëª…'ì„ í¬í•¨í•˜ëŠ” ë°˜ë³µì ì¸ êµ¬ì¡°ë¥¼ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤.
        # ì˜ˆë¥¼ ë“¤ì–´, ê° ëŒ€í•™ ì„¹ì…˜ì´ <div class="department_list02"> ê°™ì€ ê²ƒìœ¼ë¡œ ê°ì‹¸ì ¸ ìˆê³ , ê·¸ ì•ˆì— <h4>ê°€ ìˆë‹¤ë©´,
        # ì„ íƒìëŠ” "//div[@class='department_list02']//h4" ë˜ëŠ” ë” ì •í™•í•œ ê²½ë¡œê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        # html_selectëŠ” BeautifulSoup ê¸°ë°˜ì´ë¯€ë¡œ ì „ì²´ XPath ì§€ì›ì— í•œê³„ê°€ ìˆì„ ìˆ˜ ìˆì–´ CSS ì„ íƒì ì‚¬ìš©ì´ ê¶Œì¥ë©ë‹ˆë‹¤.

        # FIXME: ì•„ë˜ ì„ íƒìëŠ” `grad.cnu.ac.kr` í˜ì´ì§€ì˜ ì‹¤ì œ HTML êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ì—¬ ì •í™•í•˜ê²Œ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.
        # ê° ëŒ€í•™(ì˜ˆ: ì¸ë¬¸ëŒ€í•™, ì‚¬íšŒê³¼í•™ëŒ€í•™ ë“±)ì˜ ì´ë¦„(<h4>)ì„ í¬í•¨í•˜ëŠ” ì»¨í…Œì´ë„ˆë¥¼ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤.
        # ì˜ˆë¥¼ ë“¤ì–´, ê° ëŒ€í•™ ì„¹ì…˜ì´ <div class="college_section"> ê°™ì€ íƒœê·¸ë¡œ ë°˜ë³µëœë‹¤ë©´,
        # college_sections = html_select(html_content, "div.college_section") # ì´ëŸ° ì‹ìœ¼ë¡œ ì„¹ì…˜ì„ ë¨¼ì € ì°¾ê³ 
        # for section_html in college_sections:
        #     college_name = html_select(section_html, "h4") # ì„¹ì…˜ ë‚´ì—ì„œ h4 (ëŒ€í•™ëª…)
        #     ...

        # í˜„ì¬ëŠ” í˜ì´ì§€ ì „ì²´ì—ì„œ <h4> íƒœê·¸ ì¤‘ "ëŒ€í•™"ìœ¼ë¡œ ëë‚˜ëŠ” ê²ƒì„ ì°¾ëŠ” ë‹¨ìˆœí•œ ë°©ì‹ìœ¼ë¡œ ì‹œë„í•©ë‹ˆë‹¤.
        # ì´ëŠ” ì •í™•ë„ê°€ ë‚®ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ë°˜ë“œì‹œ ì‹¤ì œ êµ¬ì¡°ì— ë§ëŠ” ì„ íƒìë¡œ ê°œì„ í•´ì•¼ í•©ë‹ˆë‹¤.
        h4_elements = html_select(html_content, "h4")  # í˜ì´ì§€ ë‚´ ëª¨ë“  h4 íƒœê·¸

        processed_college_names = set()

        if not h4_elements:
            logger.warning(f"'{grad_info_url}' ì—ì„œ <h4> íƒœê·¸ (ëŒ€í•™ëª… í›„ë³´)ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        else:
            logger.info(f"'{grad_info_url}' ì—ì„œ {len(h4_elements)}ê°œì˜ <h4> íƒœê·¸ ë°œê²¬. 'ëŒ€í•™'ìœ¼ë¡œ ëë‚˜ëŠ”ì§€ í•„í„°ë§ ì‹œë„.")
            for name_raw in h4_elements:
                name = clean_text(name_raw)
                # "ëŒ€í•™"ìœ¼ë¡œ ëë‚˜ê³ , ë„ˆë¬´ ì§§ì§€ ì•Šìœ¼ë©°, íŠ¹ì • ì œì™¸ í‚¤ì›Œë“œê°€ ì—†ëŠ” ê²½ìš°ë¥¼ ëŒ€í•™ëª…ìœ¼ë¡œ ê°„ì£¼ (íœ´ë¦¬ìŠ¤í‹±)
                if name.endswith("ëŒ€í•™") and len(name) > 3 and name not in processed_college_names \
                        and not any(ex in name for ex in ["ê³µì§€ì‚¬í•­", "ìë£Œì‹¤"]):  # ì˜ˆì‹œ ì œì™¸ í‚¤ì›Œë“œ

                    college_code = _generate_college_code(name, prefix="gradpage")
                    # ì´ ëŒ€í•™ì˜ URLì€ grad_info_url ìì²´ë¡œ ì„¤ì •í•˜ê±°ë‚˜, ê° ëŒ€í•™ë³„ í˜ì´ì§€ê°€ ìˆë‹¤ë©´ ê·¸ URLì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.
                    # ì—¬ê¸°ì„œëŠ” grad_info_urlì„ ëŒ€í‘œ URLë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
                    colleges_data.append({
                        "code": code,
                        "name": f"{name}(ì¼ë°˜ëŒ€í•™ì›ì†Œì†)",  # ì¶œì²˜ ëª…ì‹œ
                        "url": grad_info_url,  # ì´ URLì€ ëŒ€í•™ ëŒ€í‘œ URLì´ ì•„ë‹ ìˆ˜ ìˆìŒ. ì£¼ì˜.
                        "college_type": "grad_page_college"  # ëª¨ë¸ì— ì •ì˜ëœ íƒ€ì…
                    })
                    processed_college_names.add(name)
            logger.info(f"ì¼ë°˜ëŒ€í•™ì› í˜ì´ì§€ì—ì„œ {len(colleges_data)}ê°œì˜ 'ëŒ€í•™' ë‹¨ìœ„ ì •ë³´ ì¶”ì¶œ.")

        # ë§Œì•½ ìœ„ì—ì„œ ì•„ë¬´ê²ƒë„ ì°¾ì§€ ëª»í–ˆê±°ë‚˜, "ì¼ë°˜ëŒ€í•™ì›" ìì²´ë¥¼ í•˜ë‚˜ì˜ Collegeë¡œ ë“±ë¡í•˜ê³  ì‹¶ë‹¤ë©´:
        if not colleges_data:
            logger.info(f"ì¼ë°˜ëŒ€í•™ì› í˜ì´ì§€ì—ì„œ ê°œë³„ 'ëŒ€í•™' ë‹¨ìœ„ë¥¼ ì°¾ì§€ ëª»í•´ 'ì¼ë°˜ëŒ€í•™ì›' ì „ì²´ë¥¼ í•˜ë‚˜ì˜ Collegeë¡œ ë“±ë¡í•©ë‹ˆë‹¤.")
            colleges_data.append({
                "code": "grad_school_main_unit",  # ê³ ìœ  ì½”ë“œ
                "name": "ì¼ë°˜ëŒ€í•™ì›(ì „ì²´)",
                "url": grad_info_url,
                "college_type": "grad_page_college"  # ë˜ëŠ” ë‹¤ë¥¸ íƒ€ì… (ì˜ˆ: 'general_graduate_school_itself')
            })

        _save_colleges_to_db(colleges_data, "ì¼ë°˜ëŒ€í•™ì› í˜ì´ì§€ ê¸°ë°˜ 'ëŒ€í•™' ë‹¨ìœ„")
        return colleges_data
    except Exception as e:
        logger.opt(exception=True).error(f"ì¼ë°˜ëŒ€í•™ì› í˜ì´ì§€({grad_info_url}) 'ëŒ€í•™' ë‹¨ìœ„ íƒìƒ‰ ì¤‘ ì˜ˆì™¸: {e}")
        return []


async def discover_plus_all_graduate_schools(plus_url: str = ROOT_URL) -> List[Dict]:
    """
    ROOT_URL (plus.cnu.ac.kr)ì˜ 'ëŒ€í•™ì›' ì„¹ì…˜ì—ì„œ ëª¨ë“  ëŒ€í•™ì›(ì¼ë°˜, íŠ¹ìˆ˜, ì „ë¬¸) ë§í¬ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    XPath: /html/body/div[3]/div/div[2]/ul/li/a
    """
    logger.info(f"ğŸ” Plus ({plus_url}) ì „ì²´ ëŒ€í•™ì› ëª©ë¡ íƒìƒ‰ ì‹œì‘...")
    colleges_data: List[Dict] = []
    # ì‚¬ìš©ì ì œê³µ XPath: /html/body/div[3]/div/div[2]/ul/li[1]/a (ì¼ë°˜ëŒ€í•™ì›)
    #                 /html/body/div[3]/div/div[2]/ul/li[2]/a (ê·¸ ì™¸)
    # ì „ì²´ë¥¼ í¬í•¨í•˜ëŠ” XPath: /html/body/div[3]/div/div[2]/ul/li/a
    GRADUATE_SCHOOL_LINK_XPATH = "/html/body/div[3]/div/div[2]/ul/li/a"

    try:
        with get_driver() as driver:  # Selenium ì‚¬ìš©
            driver.get(plus_url)
            WebDriverWait(driver, 15).until(
                EC.presence_of_all_elements_located((By.XPATH, GRADUATE_SCHOOL_LINK_XPATH))
            )
            grad_school_link_elements = driver.find_elements(By.XPATH, GRADUATE_SCHOOL_LINK_XPATH)

            if not grad_school_link_elements:
                logger.warning(f"Plus({plus_url})ì—ì„œ ì „ì²´ ëŒ€í•™ì› ë§í¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤ (XPath: {GRADUATE_SCHOOL_LINK_XPATH}).")
                return []

            logger.info(f"Plus({plus_url})ì—ì„œ {len(grad_school_link_elements)}ê°œì˜ ì „ì²´ ëŒ€í•™ì› ë§í¬ í›„ë³´ ë°œê²¬.")
            for idx, link_element in enumerate(grad_school_link_elements):
                name_raw = link_element.text
                name = clean_text(name_raw if name_raw else "")
                url_raw = link_element.get_attribute("href")

                if not name or not url_raw:
                    logger.warning(f"Plus ì „ì²´ ëŒ€í•™ì› ë§í¬ì—ì„œ ì´ë¦„ ë˜ëŠ” URL ëˆ„ë½ (ì¸ë±ìŠ¤: {idx}). ê±´ë„ˆëœë‹ˆë‹¤.")
                    continue

                url = urljoin(plus_url, url_raw)

                # college_type ê²°ì •: ì²« ë²ˆì§¸ ë§í¬(li[1]/a)ëŠ” ì¼ë°˜ëŒ€í•™ì›, ë‚˜ë¨¸ì§€ëŠ” íŠ¹ìˆ˜/ì „ë¬¸ëŒ€í•™ì›ìœ¼ë¡œ ê°€ì •
                # XPath ì¸ë±ìŠ¤ëŠ” 1ë¶€í„° ì‹œì‘
                college_type = "plus_general_grad" if (idx == 0) else "plus_special_grad"

                # ì½”ë“œ ìƒì„±
                code_prefix = "plus_gen_grad" if college_type == "plus_general_grad" else "plus_spec_grad"
                college_code = _generate_college_code(name, prefix=code_prefix)

                colleges_data.append({
                    "code": college_code,
                    "name": name,
                    "url": url,
                    "college_type": college_type
                })

        _save_colleges_to_db(colleges_data, "Plus ì „ì²´ ëŒ€í•™ì›")
        return colleges_data
    except Exception as e:
        logger.opt(exception=True).error(f"Plus ì „ì²´ ëŒ€í•™ì› ëª©ë¡ íƒìƒ‰ ì¤‘ ì˜ˆì™¸: {e}")
        return []


async def discover_all_colleges_entrypoint():
    """ ëª¨ë“  ì¢…ë¥˜ì˜ College ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ëŠ” í†µí•© ì§„ì…ì  í•¨ìˆ˜ """
    logger.info("ëª¨ë“  College ì •ë³´ ìˆ˜ì§‘ ì‘ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤.")

    # ê¸°ì¡´ discover_collegesì˜ ì—­í• ì„ í•˜ëŠ” í•¨ìˆ˜ í˜¸ì¶œ (plus.cnu.ac.krì˜ ì¼ë°˜ ë‹¨ê³¼ëŒ€í•™)
    await discover_plus_normal_colleges(ROOT_URL)

    # grad.cnu.ac.kr í˜ì´ì§€ì—ì„œ "ëŒ€í•™ëª…"ë“¤ì„ Collegeë¡œ ë“±ë¡
    await discover_grad_page_colleges_and_depts("https://grad.cnu.ac.kr/grad/grad/normal-grad.do")

    # plus.cnu.ac.krì˜ "ëŒ€í•™ì›" ì„¹ì…˜ ë§í¬ë“¤ì„ Collegeë¡œ ë“±ë¡
    await discover_plus_all_graduate_schools(ROOT_URL)

    # ëª¨ë“  ì‘ì—… ì™„ë£Œ í›„ DBì—ì„œ ì „ì²´ College ëª©ë¡ì„ ê°€ì ¸ì™€ì„œ ë°˜í™˜í•  ìˆ˜ë„ ìˆìœ¼ë‚˜,
    # ì—¬ê¸°ì„œëŠ” ê° í•¨ìˆ˜ê°€ DBì— ì €ì¥í•˜ëŠ” ê²ƒìœ¼ë¡œ ì²˜ë¦¬í•˜ê³ , ë°˜í™˜ê°’ì€ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ.
    # ìŠ¤ì¼€ì¤„ëŸ¬ì—ì„œëŠ” DBì—ì„œ ì§ì ‘ College ëª©ë¡ì„ ì½ì–´ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ì§„í–‰.
    logger.info("ëª¨ë“  College ì •ë³´ ìˆ˜ì§‘ ì‘ì—… ì™„ë£Œ.")